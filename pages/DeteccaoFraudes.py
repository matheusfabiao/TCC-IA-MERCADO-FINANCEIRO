# Ignorar avisos
import warnings
warnings.filterwarnings('ignore')

# Importando bibliotecas necess√°rias
import time
import streamlit as st
import pandas as pd
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, precision_recall_curve, roc_curve, auc

# C√≥digo de Detec√ß√£o de Fraudes em Transa√ß√µes de Cart√£o de Cr√©dito
# Autor: Matheus Fabi√£o da Costa Pereira
# Data de Cria√ß√£o: 30/10/2023

# Fun√ß√£o para exibir o t√≠tulo do aplicativo
def titulo_app():
    # st.write("TCC - Trabalho de Conclus√£o de Curso")
    # st.write("Deploy de Modelo Preditivo de Machine Learning")
    # st.write("Previs√£o do Pre√ßo de Fechamento das A√ß√µes")
    # st.write("Autor: Matheus Fabi√£o da Costa Pereira")
    # st.write("Autor: Matheus Davi de Serrano Ara√∫jo Meireles")
    # st.write("Orientador: Leandro Santana de Melo")
    st.title("Logistic Regression Model")
    

# Fun√ß√£o para carregar o dataset
@st.cache_data
def carrega_dataset():
    caminho_dados = r'C:\Users\Matheus Fabiao\Desktop\TCC-IA-MERCADO-FINANCEIRO\data\creditcard.csv'
    try:
        dados = pd.read_csv(caminho_dados)
        return dados
    except Exception as e:
        st.error(f'Erro ao carregar dataset: {str(e)}')
        return None


# Fun√ß√£o para exibir o dataset
def exibe_dataset(dados) -> None:
    # Exibir os √∫ltimos 5 dados do Dataset
    st.subheader('Dataset: Detec√ß√£o de Fraudes')
    st.dataframe(dados)


# Fun√ß√£o para exibir informa√ß√µes sobre o dataset
def info_dataset():
    # Exibe um expander ao clicar no bot√£o de ajuda
    with st.expander("‚ÑπÔ∏è **Informa√ß√µes do Dataset**"):
        st.write('''**Time:** O tempo decorrido desde a primeira transa√ß√£o no conjunto de dados, medido em segundos.             
            **V1-V28:** Recursos anonimizados que representam v√°rias caracter√≠sticas da transa√ß√£o (por exemplo, hora, localiza√ß√£o, etc.).             
            **Amount:** O valor da transa√ß√£o.             
            **Class:** R√≥tulo bin√°rio que indica se a transa√ß√£o √© fraudulenta (1) ou n√£o (0).''')


# Fun√ß√£o para remover a coluna 'Time' dos dados
def remove_tempo(dados):
    # Removendo a coluna 'Time', por n√£o ser relevante
    dados = dados.drop(['Time'], axis=1)
    return dados


# Fun√ß√£o para separar transa√ß√µes em fraudes e n√£o fraudes
def separa_fraudes(dados):
    # Separando as transa√ß√µes em n√£o fraudes
    nao_fraudes = dados[dados['Class']==0]
    st.write('O n√∫mero de transa√ß√µes v√°lidas √© de:', len(nao_fraudes))

    # Separando as transa√ß√µes em fraudes
    fraudes = dados[dados['Class']==1]
    st.write('O n√∫mero de transa√ß√µes fraudulentas √© de:', len(fraudes))
    
    return nao_fraudes, fraudes


# Fun√ß√£o para criar um conjunto de valida√ß√£o
def amostra_validacao(nao_fraudes, fraudes, dados):
    # Criando um conjunto de valida√ß√£o com 15 transa√ß√µes de cada classe
    validacao_nao_fraudes = nao_fraudes.sample(15)
    validacao_fraudes = fraudes.sample(15)
    # Concatenando os dois conjuntos de valida√ß√£o
    validacao = pd.concat([validacao_nao_fraudes, validacao_fraudes], ignore_index=True)
    # Removendo as transa√ß√µes de valida√ß√£o do DataFrame original
    dados = dados.drop(validacao_nao_fraudes.index)
    dados = dados.drop(validacao_fraudes.index)
    # Criando o DataFrame com os valores reais, para comparar com as previs√µes
    validacao_real = validacao.Class
    # Remover a coluna alvo 'Class'
    validacao = validacao.drop(['Class'], axis=1)
    return validacao, dados, validacao_real


# Fun√ß√£o para preparar os dados para treinamento
def prepara_dados(dados):
    # Separando as caracter√≠sticas (x) e as classes alvo (y) dos dados
    X = dados.drop(['Class'], axis=1)
    Y = dados['Class']
    
    # Utiliza√ß√£o do SMOTE para a sobreamostragem
    smote = SMOTE(random_state=42)
    X_reamostrado, y_reamostrado = smote.fit_resample(X, Y)
    return X_reamostrado, y_reamostrado


# Fun√ß√£o para separar os dados em conjuntos de treinamento e teste
def separa_dados(X_reamostrado, y_reamostrado, split):  
    x_treino, x_teste, y_treino, y_teste = train_test_split(X_reamostrado, y_reamostrado, train_size=split, random_state=42, stratify=y_reamostrado)
    return x_treino, x_teste, y_treino, y_teste


# Fun√ß√£o para criar o modelo de regress√£o log√≠stica
def cria_modelo(Hiperparametros):
    # Cria o modelo de regress√£o log√≠stica
    modelo = LogisticRegression(penalty= Hiperparametros['Penality'],
                                tol= float(Hiperparametros['Tol']),
                                solver= Hiperparametros['Solver'],
                                max_iter= Hiperparametros['Max_Iteration'])
    return modelo


# Fun√ß√£o para treinar o modelo
def treina_modelo(modelo, Xtreino, Ytreino):
    modelo.fit(Xtreino, Ytreino)


# Fun√ß√£o para fazer previs√µes
def faz_previsao(modelo, Xteste):
    # Fazendo previs√µes no conjunto de teste
    previsao = modelo.predict(Xteste)
    return previsao


# Fun√ß√£o para calcular m√©tricas de desempenho
def calcula_metricas(Yteste, Previsao):
    # Avaliando o modelo usando as principais m√©tricas
    precisao = precision_score(Yteste, Previsao)
    recall = recall_score(Yteste, Previsao)
    f1 = f1_score(Yteste, Previsao)
    acuracia = accuracy_score(Yteste, Previsao)
    matriz_confusao = confusion_matrix(Yteste, Previsao)
    return precisao, recall, f1, acuracia, matriz_confusao


# Fun√ß√£o para exibir m√©tricas de desempenho
def exibe_metricas(Precisao, Recall, F1, Acuracia, Matriz_confusao):
        # Avaliando o modelo usando as principais m√©tricas
        col1, col2 = st.columns(2)
        col1.write(f'Precis√£o: {Precisao:.2f}')
        col1.write(f'Recall: {Recall:.2f}')
        col1.write(f'F1-Score: {F1:.2f}')
        col1.write(f'Acur√°cia: {Acuracia:.2f}')
        col2.subheader('Matriz de Confus√£o:')
        col2.write(Matriz_confusao)
    
def ajuda_config():
    # Adiciona um bot√£o na sidebar
    if st.sidebar.button('Ajuda com os Hiperpar√¢metros'):
        # Exibe um expander ao clicar no bot√£o de ajuda
        with st.expander("‚ÑπÔ∏è **Informa√ß√µes de Ajuda**"):
            st.write('''
                    **Intervalo de Tempo:** quantidade total de dados do ativo nos √∫ltimos 'n' anos.
                    
                    **Divis√£o dos Dados:** dividir o total de dados em x% para treino da IA. Recomendado entre 0.7 e 0.8

                    **Dropout:** desativa aleatoriamente neur√¥nios durante o treinamento para evitar *overfitting*.
                    Recomendado: entre 0.2 e 0.5
 
                    **N√∫mero de Amostras:** n√∫mero de exemplos de dados que a IA analisa de uma vez durante o treinamento.
                    Quanto mais alto mais r√°pido o treinamento, por√©m exigir√° mais do seu hardware.
 
                    **Janela de Entrada:** √© como uma "mem√≥ria" que a rede utiliza para processar sequ√™ncias de dados, lembrando de informa√ß√µes importantes ao longo do tempo.
 
                    **√âpocas:** quantidade de vezes que a IA percorre todo o conjunto de dados durante o treinamento. Quanto mais alto mais demorado o treinamento, por√©m,
                    mais bem treinada ela ser√°.
                    ''')

    
# CHAMADA DE FUN√á√ïES

st.set_page_config(
    page_title='Detec√ß√£o de Fraudes Banc√°rias',
    page_icon='üí∞'
)

# T√≠tulo
titulo_app()

# Programando a Barra Lateral de Navega√ß√£o da Aplica√ß√£o Web
# Cabe√ßalho lateral
st.sidebar.header('Dataset e Hiperpar√¢metros')
st.sidebar.markdown("""**Configure o Modelo de ML**""")

ajuda_config()

divisao = st.sidebar.select_slider('Escolha o Percentual de Divis√£o dos Dados em Treino e Teste (padr√£o = 80/20):', (0.5, 0.6, 0.65, 0.7, 0.75, 0.8, 0.9), 0.8)

Solver = st.sidebar.selectbox('Algoritmo (padr√£o = lbfgs)', ('lbfgs', 'newton-cg', 'liblinear', 'sag'))
Penality = st.sidebar.radio("Regulariza√ß√£o (padr√£o = l2):", ('none', 'l1', 'l2', 'elasticnet'), 2)
Tol = st.sidebar.selectbox('''Toler√¢ncia Para Crit√©rio de Parada                               
                                (padr√£o = 1e-4):''', ('1e-4', '1e-5', '1e-6'))
Max_Iteration = st.sidebar.select_slider("N√∫mero de Itera√ß√µes (padr√£o = 100):", (50, 100, 500, 700, 1000), 100)


# Dicion√°rio Para os Hiperpar√¢metros
# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html
# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html
hiperparametros = { 'Penality':Penality, 'Tol':Tol, 'Max_Iteration':Max_Iteration, 'Solver':Solver }

# Exibir os √∫ltimos 5 dados do Dataset
base_dados = carrega_dataset()
# pre_processar_dados(base_dados)
exibe_dataset(base_dados)
info_dataset()

# PREPARA√á√ÉO DOS DADOS

base_dados = remove_tempo(base_dados)

st.subheader('Divis√£o dos Conjuntos de Dados')
# Separando as transa√ß√µes em fraude e n√£o fraude
nao_fraudes, fraudes = separa_fraudes(base_dados)
validacao, dados, validacao_real = amostra_validacao(nao_fraudes, fraudes, base_dados)

X_reamostrado, y_reamostrado = prepara_dados(base_dados)
x_treino, x_teste, y_treino, y_teste = separa_dados(X_reamostrado, y_reamostrado, divisao)

# Programando o Bot√£o de A√ß√£o
if(st.sidebar.button("Clique Para Treinar o Modelo de Random Forest Classifier")):
    
    # Barra de progress√£o
    with st.spinner('Separando os Dados...'):
        time.sleep(1)

    # Info de sucesso
    st.success("Dados de Treino e Teste Prontos!")
    
    # Cria o modelo
    st.subheader('Treinamento do Modelo')
    linear_regression = cria_modelo(hiperparametros)
    
    try:
        # Treina o modelo
        treina_modelo(linear_regression, x_treino, y_treino)
    
        # Barra de progress√£o
        barra_progressao = st.progress(0)
        
        # Mostra a barra de progress√£o com percentual de conclus√£o
        for porcentagem_completada in range(100):
            time.sleep(0.1)
            barra_progressao.progress(porcentagem_completada + 1)
            
        # Info para o usu√°rio
        with st.spinner('Treinando o Modelo...'):
            time.sleep(1)

        # Info de sucesso
        st.success("Modelo Treinado!")
    except Exception as e:
        st.error(f"Erro durante o treinamento do modelo: {str(e)}")
        
    try:    
        previsao = faz_previsao(linear_regression, x_teste)
    
        # Avalia√ß√£o do modelo
        st.subheader('Avalia√ß√£o do Modelo')
        precisao, recall, f1, acuracia, matriz_confusao = calcula_metricas(y_teste, previsao)
        exibe_metricas(precisao, recall, f1, acuracia, matriz_confusao)
    except Exception as e:
        st.error(f"Erro durante o c√°lculo de m√©tricas ou previs√µes: {str(e)}")
        
    # Teste com o modelo
    st.subheader('Valida√ß√£o do Modelo')
    predict = linear_regression.predict(validacao)
    dados = pd.DataFrame({'real':validacao_real, 'previsao':predict})
    st.dataframe(dados)